import { GoogleGenerativeAI } from '@google/generative-ai'
import { createClient } from '@supabase/supabase-js'
import { NextResponse } from 'next/server'

export async function POST(req) {
  try {
    const apiKey = process.env.GEMINI_API_KEY || ""
    if (!apiKey) throw new Error('Falta la GEMINI_API_KEY')

    const genAI = new GoogleGenerativeAI(apiKey)
    const supabase = createClient(
      process.env.NEXT_PUBLIC_SUPABASE_URL,
      process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY
    )

    const { message, userId } = await req.json()

    // ==========================================
    // üß† FASE 1: GENERAR EMBEDDING (VECTOR)
    // ==========================================
    // Convertimos la pregunta del usuario en n√∫meros
    const embeddingModel = genAI.getGenerativeModel({ model: "text-embedding-004" })
    const embeddingResult = await embeddingModel.embedContent(message)
    const vectorUsuario = embeddingResult.embedding.values

    // ==========================================
    // üß† FASE 1.5: VERIFICAR CACH√â (MEMORIA)
    // ==========================================
    // Buscamos si alguien ya pregunt√≥ algo MUY parecido (umbral alto: 0.85 o 0.9)
    const { data: memoriaEncontrada } = await supabase
      .rpc('buscar_similares', {
        query_embedding: vectorUsuario,
        match_threshold: 0.90, // ¬°Alto! Queremos casi la misma pregunta
        match_count: 1
      })

    if (memoriaEncontrada && memoriaEncontrada.length > 0) {
      console.log('‚ö° MEMORIA: Respuesta reutilizada del cach√©')
      return NextResponse.json({ 
        response: memoriaEncontrada[0].respuesta_bot,
        source: 'Memoria Inteligente (Cache)' 
      })
    }

    // ==========================================
    // üîç FASE 2: B√öSQUEDA SEM√ÅNTICA (VECTORES)
    // ==========================================
    
    // Buscamos en la base de conocimientos usando la funci√≥n que creamos en SQL (match_documents)
    // Nota: Umbral 0.5 es un buen equilibrio. Si es muy estricto, b√°jalo a 0.4
    const { data: documentos, error } = await supabase
      .rpc('match_documents', {
        query_embedding: vectorUsuario, 
        match_threshold: 0.50, 
        match_count: 5 
      })

    if (error) console.error('Error Supabase:', error)

    let contexto = ""
    let sourceLabel = "Base de Conocimiento"

    if (documentos && documentos.length > 0) {
      contexto = documentos.map(doc => 
        `-- REGLAMENTO: ${doc.titulo} (${doc.categoria}) --\n${doc.contenido}\n`
      ).join('\n\n')
    } else {
      contexto = "No se encontr√≥ informaci√≥n relevante en los reglamentos."
      sourceLabel = "Conocimiento General (Advertencia: Puede no ser exacto)"
    }

    // ==========================================
    // ü§ñ FASE 3: GENERACI√ìN CON GEMINI
    // ==========================================
    const model = genAI.getGenerativeModel({ model: "gemini-2.0-flash" })
    
    const prompt = `
      Eres el Asistente Acad√©mico Oficial de la Universidad de Guayaquil.
      
      TU OBJETIVO: Responder preguntas sobre reglamentos bas√°ndote EXCLUSIVAMENTE en el contexto proporcionado.

      CONTEXTO RECUPERADO:
      ${contexto}

      PREGUNTA DEL USUARIO: "${message}"

      INSTRUCCIONES:
      1. Analiza el contexto. Si encuentras la respuesta, expl√≠cala claramente.
      2. CITA LA FUENTE: Siempre menciona qu√© reglamento o art√≠culo usaste (ej: "Seg√∫n el Art. 22 del Reglamento...").
      3. Si el contexto dice "No se encontr√≥ informaci√≥n", responde: "Lo siento, no tengo informaci√≥n sobre ese tema espec√≠fico en mis reglamentos actuales."
      4. No inventes art√≠culos ni leyes que no est√©n en el texto.
    `

    const result = await model.generateContent(prompt)
    const responseText = result.response.text()

    // ==========================================
    // üíæ FASE 4: GUARDADO DE LOGS
    // ==========================================
    if (userId) {
       // Guardamos el log para futuras mejoras o cach√©
       await supabase.from('logs_consultas').insert([{
        usuario_id: userId,
        pregunta: message,
        respuesta_bot: responseText,
        embedding: vectorUsuario // Guardamos el vector por si quieres usar cach√© despu√©s
      }])
    }

    return NextResponse.json({ 
      response: responseText,
      source: sourceLabel
    })

  } catch (error) {
    console.error('üî¥ ERROR:', error)
    return NextResponse.json({ error: error.message }, { status: 500 })
  }
}